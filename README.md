# EM-Based Transfer Learning for Gaussian Causal Models Under Covariate and Target Shift

Code and experiments for our paper:

> **â€œEM-Based Transfer Learning for Gaussian Causal Models Under Covariate and Target Shiftâ€ (ICDM 2025, regular paper)**

---

## âœ¨ Whatâ€™s in this repo
- Implementations:
  - Kiiveri EM (classical latent-variable EM)
  - **1st-order EM** (gradient/GEM variant)
  - ECME and PX-EM accelerations
- Reproducible experiments for:
  - Synthetic 7-node SEM
  - 64-node MAGIC-IRRI network
  - Sachs single-cell signaling dataset
- Utilities for DAG-constrained Gaussian SEM fitting

> If youâ€™re here to **impute a fully missing target variable `T`** in a known DAG under domain shift, jump to [Quickstart](#quickstart).

---

## ğŸ“¦ Environment

- Python >= 3.10
- See [`requirements.txt`](./requirements.txt) for runtime deps
- Docs deps in [`docs/requirements.txt`](./docs/requirements.txt)

Docker (optional):
- We provide a Docker build recipe in `DockerfileDocs` (rename to `Dockerfile` if you prefer).
- Add any system libs your extras need (BLAS, graphviz, etc.).

---

## ğŸš€ Quickstart

```bash
# 1) create env
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 2) run a small synthetic demo
python src/demos/demo_synthetic_first_order_em.py \
  --seed 42 --iters 1_000 --tol 1e-6

# 3) reproduce a Sachs run (example)
python src/experiments/sachs/run_em_pipeline.py \
  --config configs/sachs/t_as_latent.yaml

Outputs (plots, CSV metrics) land in outputs/ by default.

ğŸ“ Repo layout
.
â”œâ”€ src/
â”‚  â”œâ”€ core/          # SEM/DAG primitives: lmfit, fitdag, E-step, etc.
â”‚  â”œâ”€ methods/       # kiiveri_em.py, first_order_em.py, ecme.py, px_em.py
â”‚  â”œâ”€ experiments/   # scripts to reproduce paper tables/figures
â”‚  â””â”€ demos/         # small runnable examples
â”œâ”€ tests/            # unit tests (pytest)
â”œâ”€ configs/          # YAML configs for experiments
â”œâ”€ data/             # (empty) put datasets or symlinks here; see below
â”œâ”€ docs/             # Sphinx (or mkdocs) documentation
â”œâ”€ requirements.txt
â”œâ”€ docs/requirements.txt
â”œâ”€ DockerfileDocs
â””â”€ README.md

ğŸ“š Datasets

Sachs: see instructions in data/README.md (we do not commit raw data).

MAGIC-IRRI: pointers and preprocessing scripts in data/magic_irri/.

Synthetic: generated on the fly by scripts in src/experiments/synthetic/.

ğŸ§  Methods overview

Kiiveri EM: classic EM with closed-form E-step for one latent (the target T) and GLS M-step.

First-order EM: one gradient ascent step on the DAG-constrained covariance per iteration â€” O(pÂ²) per step.

ECME: observed-likelihood maximization for the variance of T to accelerate convergence.

PX-EM: parameter expansion in the T direction to improve curvature.

Each method exposes a unified interface:
dag_fit, Sigma_hat, (mu_hat), iters, converged = method.fit(X_obs, idx_t, amat, Sigma_init, **kwargs)

ğŸ§ª Reproducing paper results

See src/experiments/* and the corresponding configs/*.yaml.
We export:

Per-experiment CSVs with MAE, RMSE, RÂ²

Scatter plots (true vs imputed T)

Logs with likelihood/gap diagnostics

Example:
python src/experiments/magic_irri/run_magic.py --config configs/magic_irri/cov_shift.yaml

ğŸ”¬ Citing

If you use this code, please cite:
@inproceedings{javidian2025emtransfer,
  title={EM-Based Transfer Learning for Gaussian Causal Models Under Covariate and Target Shift},
  author={Javidian, Mohammad Ali},
  booktitle={IEEE International Conference on Data Mining (ICDM)},
  year={2025}
}

ğŸ“„ License

MIT â€” see the [LICENSE](./LICENSE) file.
SPDX-License-Identifier: MIT

ğŸ¤ Contributing

PRs and issues welcome. Run pytest before submitting.

ğŸ“¨ Contact

Mohammad Ali Javidian â€” javidianma@appstate.edu
